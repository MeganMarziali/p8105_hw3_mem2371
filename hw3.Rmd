---
title: "Homework 3"
author: Megan Marziali
output: github_document
---

## Beginning infrastructure

This code chunk calls any relevant libraries and setting options.

```{r, message = FALSE}
library(tidyverse)
library(p8105.datasets)
library(ggridges)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

#### Loading instacart dataset

The following code chunk loads the Instacart dataset

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. Obervations are the level of items in orders by users. There are user / order variables -- user_id, order id, order day, and order hour. There are also item variables -- name, aisle, department and some numeric codes.

#### Answering specific questions

The following code is to check how many aisles.

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

Let's make a plot!

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Let's make a table!

```{r}
instacart %>% 
  filter(aisle %in% c(
    "baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

Apples vs ice cream ... 

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```


## Problem 2

The following code is to load in the accelerometer data.

```{r message=FALSE}
accel_df = 
  read_csv("./problem2/accel_data.csv",
           na = "") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity",
    names_prefix = "activity_",
    values_to = "measures"
  ) %>% 
  mutate(
    day_type = recode(
      day, 
      Monday = "Weekday",
      Tuesday = "Weekday",
      Wednesday = "Weekday",
      Thursday = "Weekday",
      Friday = "Weekday", 
      Saturday = "Weekend",
      Sunday = "Weekend"),
    day = factor(day),
    day = forcats::fct_relevel(day, c("Monday",
                                      "Tuesday",
                                      "Wednesday",
                                      "Thursday",
                                      "Friday",
                                      "Saturday",
                                      "Sunday")),
    activity = as.integer(activity)
  )
```

This dataset includes accelerometer data collected from a 65 year old patient. The variables included are `r names(accel_df)`. There are a total of `r nrow(accel_df)` rows and `r ncol(accel_df)` columns. The total number of **activity** measurements taken is `r max(pull(accel_df, activity))`. Measurements were taken every `r levels(pull(accel_df, day))`, for a total of `r max(pull(accel_df, week))` weeks and `r max(pull(accel_df, day_id))` days.

The value of the accelerometer readings as per the **measures** variable ranges from `r min(pull(accel_df, measures))` to `r max(pull(accel_df, measures))`. The mean of the accelerometer readings is `r mean(pull(accel_df, measures), n = 2)`, with a standard deviation of `r sd(pull(accel_df, measures), n = 2)`. The median is `r median(pull(accel_df, measures), n = 2)`, with an IQR of `r IQR(pull(accel_df, measures), n = 2)`. 

### Aggregating data

The following code makes a table, aggregated by total activity per day.

```{r message=FALSE}
accel_agg = 
  accel_df %>% 
  group_by(day) %>% 
  summarize(
    total_activity = sum(measures)
  ) %>% 
  knitr::kable(digits = 1)
```

It seems that the patient is the least active on Saturdays, and the most active on Fridays. The patient is somewhat active on Mondays, Tuesdays, and Sundays but more active on Wednesdays, Thursdays and Fridays.

```{r message = FALSE}
accel_df %>% 
  group_by(day_id, day) %>% 
  summarize(
    activity_time = sum(measures)
  ) %>% 
  ggplot(aes(x = activity_time, color = day)) +
  geom_density()
```

## Problem 3

The following code loads in the appropriate dataset.

```{r}
data("ny_noaa")
```

The following code cleans and tidies the data.



